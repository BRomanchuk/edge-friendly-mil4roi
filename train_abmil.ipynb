{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-27 19:25:42.915417: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-27 19:25:42.916699: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-27 19:25:42.940747: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-27 19:25:42.941160: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-27 19:25:43.251739: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mil.data.datasets import mnist_bags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bags_train = np.load('train_dp_all_filt_features.npy')\n",
    "# # bags_test = np.load('val_dp_all_filt_features.npy')\n",
    "# bags_test = np.load('test_dp_all_filt_features.npy')\n",
    "\n",
    "\n",
    "# y_train = np.load('train_dp_all_filt_labels.npy')\n",
    "# # y_test = np.load('val_dp_all_filt_labels.npy')\n",
    "# y_test = np.load('test_dp_all_filt_labels.npy')\n",
    "\n",
    "# fpaths_train = np.load('train_dp_all_filt_files.npy')\n",
    "# # fpaths_test = np.load('val_dp_all_filt_files.npy')\n",
    "# fpaths_test = np.load('test_dp_all_filt_files.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bags_train = np.load('sod4sb_train_features.npy')\n",
    "bags_test = np.load('sod4sb_val_features.npy')\n",
    "\n",
    "y_train = np.load('sod4sb_train_labels.npy')\n",
    "y_test = np.load('sod4sb_val_labels.npy')\n",
    "\n",
    "fpaths_train = np.load('sod4sb_train_files.npy')\n",
    "fpaths_test = np.load('sod4sb_val_files.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bags_train = np.load('train_dp_filt_features.npy')\n",
    "# bags_test = np.load('val_dp_filt_features.npy')\n",
    "\n",
    "# y_train = np.load('train_dp_filt_labels.npy')\n",
    "# y_test = np.load('val_dp_filt_labels.npy')\n",
    "\n",
    "# fpaths_train = np.load('train_dp_filt_files.npy')\n",
    "# fpaths_test = np.load('val_dp_filt_files.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# maximum  number of instances in the training set\n",
    "max_len_train = np.max([len(bag) for bag in bags_train])\n",
    "max_len_test = np.max([len(bag) for bag in bags_test])\n",
    "\n",
    "max_ = np.max([max_len_train, max_len_test])\n",
    "max_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bags_train_1D = bags_train\n",
    "bags_test_1D = bags_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mil.metrics import AUC, BinaryAccuracy, Sensibility, Specificity\n",
    "from mil.validators import KFold\n",
    "from mil.trainer.trainer import Trainer\n",
    "from mil.models import SVC\n",
    "from mil.bag_representation.mapping import DiscriminativeMapping\n",
    "from mil.preprocessing import StandarizerBagsList, NormalizeBagsImage\n",
    "\n",
    "from mil.models.bag_level.deep_attention import AttentionDeepPoolingMil\n",
    "from mil.utils.utils import get_samples_weight\n",
    "from mil.utils.padding import Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-27 19:25:50.723854: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-04-27 19:25:50.749466: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer()\n",
    "\n",
    "metrics = [AUC, BinaryAccuracy, Sensibility, Specificity]\n",
    "model = AttentionDeepPoolingMil(gated=False, threshold=0.2)\n",
    "pipeline = [('padding', Padding(max_len=max_))]\n",
    "\n",
    "trainer.prepare(model, preprocess_pipeline=pipeline ,metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 5ms/step\n",
      "43/43 [==============================] - 0s 4ms/step\n",
      "43/43 [==============================] - 0s 6ms/step\n",
      "43/43 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 201s 99s/step - train_auc: 0.9741 - train_binaryaccuracy: 0.9236 - train_sensibility: 0.8765 - train_specificity: 0.9709 - val_auc: 0.9549 - val_binaryaccuracy: 0.9068 - val_sensibility: 0.8441 - val_specificity: 0.9743\n"
     ]
    }
   ],
   "source": [
    "valid = KFold(n_splits=2, shuffle=True)\n",
    "\n",
    "history = trainer.fit(bags_train, y_train, validation_strategy=valid, sample_weights='balanced',\n",
    "                      verbose=1, model__epochs=20, model__batch_size=4, model__verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.91451156\n",
      "0.95961046\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'auc': 0.9643493,\n",
       "  'binaryaccuracy': 0.92218184,\n",
       "  'sensibility': 0.90261626,\n",
       "  'specificity': 0.94177586},\n",
       " {'auc': 0.9548716,\n",
       "  'binaryaccuracy': 0.90684134,\n",
       "  'sensibility': 0.84410113,\n",
       "  'specificity': 0.97432023}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.mean([e['binaryaccuracy'] for e in history['metrics_val']]))\n",
    "print(np.mean([e['auc'] for e in history['metrics_val']]))\n",
    "history['metrics_val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'auc': 0.94389886,\n",
       " 'binaryaccuracy': 0.9051724,\n",
       " 'sensibility': 0.84166664,\n",
       " 'specificity': 0.97321427}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.predict_metrics(bags_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 5ms/step\n",
      " 1/86 [..............................] - ETA: 1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcloud-ai/.newyolovenv310/lib/python3.10/site-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 1s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "# positive instances with more than 0.4 in attention weight\n",
    "pos_test = trainer.get_positive_instances(bags_test)\n",
    "pos_train = trainer.get_positive_instances(bags_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_index, patch_index in pos_test.numpy():\n",
    "    fpath = fpaths_test[img_index]\n",
    "    image = cv2.imread(fpath)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    patches = utils.resize_and_crop(image, target_size=(1904, 1120), patch_size=224, half_patch=True)\n",
    "    plt.imshow(patches[patch_index])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_index, patch_index in pos_train.numpy():\n",
    "    fpath = fpaths_train[img_index]\n",
    "    image = cv2.imread(fpath)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    patches = utils.resize_and_crop(image, target_size=(1904, 1120), patch_size=224, half_patch=True)\n",
    "    plt.imshow(patches[patch_index])\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
